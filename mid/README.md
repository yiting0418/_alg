# KNN演算法實作

### 題目
KNN演算法 Iris資料集分類實作

### 12/30口試後更新 KNN與K-Means算法實作與比較分析
使用[Gemini](https://gemini.google.com/share/fd3a3426caeb)新增使用K-Means自動分群的部分，並輸出結果圖進行比對。
學習心得：透過實作加深對於分類與分群之差別比較，分群的效果好壞取決於隨機選取中心點的位置，可以多設定幾次讓他記錄準確率最高的結果，但因為K-Means屬於非監督式學習，是讓資料自動分群，沒有標準答案，所以效果不會比KNN好。

### 步驟
#### 1. 距離計算 (Euclidean Distance)
使用**歐式距離**計算點與點之間的距離，計算公式如下：

$$d(a, b) = \sqrt{\sum_{i=1}^{n} (a_i - b_i)^2}$$

#### 2. 預測流程 (`knn_predict`)
(1).  **算距離**：算出這個測試點跟所有訓練資料的距離。
(2).  **找鄰居**：把距離由小到大排序，選出最近的 $k$ 個鄰居（這裡設定 $k=5$）。
(3).  **多數決 (Majority Voting)**：依據 $k$ 個鄰居大多屬於哪一類，就預測它是那一類。

### 執行結果

* **參數設定**: $k=5$
* **資料集**: Iris (150 筆資料)
* **訓練/測試比例**: 80% / 20%
* **視覺化**:
    * 圓點 (Train): 訓練資料原本的分佈。
    * 叉號 (Test Predict): 測試資料的預測結果。

程式跑完後會顯示樣本總數、猜對幾題，以及最後的準確率。
